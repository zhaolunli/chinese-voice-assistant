"""æ™ºèƒ½è¯­éŸ³å”¤é†’ç³»ç»Ÿ - åŒé˜¶æ®µè¯†åˆ«ç‰ˆ"""
import time
import threading
import numpy as np
import pyaudio
import sherpa_onnx
from pathlib import Path

from .config import (
    MODELS_DIR,
    SAMPLE_RATE,
    CHUNK_SIZE,
    RECORD_SECONDS,
    SILENCE_THRESHOLD,
    MAX_SILENCE_FRAMES,
    MIN_RECORD_FRAMES,
    DEFAULT_WAKE_WORDS,
    CONFIG_DIR,
)
from .react_agent import ReactAgent


class SmartWakeWordSystem:
    """æ™ºèƒ½è¯­éŸ³å”¤é†’ç³»ç»Ÿ - åŒé˜¶æ®µè¯†åˆ«ç‰ˆ"""

    def __init__(self, models_dir=None, enable_voice=True):
        self.models_dir = Path(models_dir) if models_dir else MODELS_DIR
        self.running = False
        self.sample_rate = SAMPLE_RATE
        self.enable_voice = enable_voice

        # æ‰§è¡Œçº¿ç¨‹é”ï¼ˆç¡®ä¿åŒä¸€æ—¶é—´åªæœ‰ä¸€ä¸ªå‘½ä»¤åœ¨æ‰§è¡Œï¼‰
        self.execution_lock = threading.Lock()

        print("æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹...")

        # é˜¶æ®µ1: KWSæ¨¡å‹ï¼ˆè½»é‡çº§ï¼‰
        self.kws_model = self.create_kws_model()

        # é˜¶æ®µ2: ASRæ¨¡å‹ï¼ˆé‡é‡çº§ï¼‰
        self.asr_model = self.create_asr_model()

        # React Agent (é›†æˆ MCP)
        self.agent = ReactAgent()
        print("æ­£åœ¨å¯åŠ¨ MCP Servers...")
        if not self.agent.start():
            raise RuntimeError("å¯åŠ¨ MCP Server å¤±è´¥")

        print(f"âœ“ KWSæ¨¡å‹å·²åŠ è½½")
        print(f"âœ“ ASRæ¨¡å‹å·²åŠ è½½")
        print(f"âœ“ MCP Servers å·²å¯åŠ¨")
        print(f"è¯­éŸ³æ’­æŠ¥: {'å¼€å¯' if enable_voice else 'å…³é—­'}")

    def create_kws_model(self):
        """åˆ›å»ºKWSå…³é”®è¯æ£€æµ‹æ¨¡å‹"""
        kws_dir = self.models_dir / "sherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01"

        if not kws_dir.exists():
            raise FileNotFoundError(f"KWSæ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {kws_dir}")

        # åˆ›å»ºå…³é”®è¯æ–‡ä»¶ï¼ˆæ ¼å¼ï¼šæ‹¼éŸ³éŸ³èŠ‚ @ä¸­æ–‡ï¼‰
        keywords_file = CONFIG_DIR / "keywords.txt"
        if not keywords_file.exists():
            print("âš ï¸  åˆ›å»ºé»˜è®¤å…³é”®è¯æ–‡ä»¶...")
            keywords_file.parent.mkdir(parents=True, exist_ok=True)
            with open(keywords_file, 'w', encoding='utf-8') as f:
                # æ ¼å¼ï¼šæ‹¼éŸ³éŸ³èŠ‚(ç©ºæ ¼åˆ†éš”) @ä¸­æ–‡
                # ä½¿ç”¨å¸¦å£°è°ƒçš„æ‹¼éŸ³éŸµæ¯ï¼Œç©ºæ ¼åˆ†éš”
                f.write("x iÇo zh Ã¬ @å°æ™º\n")
                f.write("n Ç h Ço zh Ã¹ sh Ç’u @ä½ å¥½åŠ©æ‰‹\n")
                f.write("zh Ã¬ n Ã©ng zh Ã¹ sh Ç’u @æ™ºèƒ½åŠ©æ‰‹\n")

        kws = sherpa_onnx.KeywordSpotter(
            tokens=str(kws_dir / "tokens.txt"),
            encoder=str(kws_dir / "encoder-epoch-12-avg-2-chunk-16-left-64.onnx"),
            decoder=str(kws_dir / "decoder-epoch-12-avg-2-chunk-16-left-64.onnx"),
            joiner=str(kws_dir / "joiner-epoch-12-avg-2-chunk-16-left-64.onnx"),
            num_threads=2,
            keywords_file=str(keywords_file),
            provider="cpu",
        )

        print(f"ğŸ“‹ åŠ è½½å…³é”®è¯: {keywords_file}")
        return kws

    def create_asr_model(self):
        """åˆ›å»ºASRå®Œæ•´è¯†åˆ«æ¨¡å‹"""
        model_file = self.models_dir / "sherpa-onnx-paraformer-zh-2024-03-09" / "model.int8.onnx"
        tokens_file = self.models_dir / "sherpa-onnx-paraformer-zh-2024-03-09" / "tokens.txt"

        if not model_file.exists():
            raise FileNotFoundError(f"ASRæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_file}")

        recognizer = sherpa_onnx.OfflineRecognizer.from_paraformer(
            str(model_file),
            str(tokens_file),
            num_threads=2,
            sample_rate=self.sample_rate,
            feature_dim=80,
            decoding_method="greedy_search",
            debug=False,
            provider="cpu"
        )
        return recognizer

    def _play_beep_fast(self):
        """æ’­æ”¾å¿«é€Ÿæç¤ºéŸ³ï¼ˆéé˜»å¡ï¼‰"""
        def beep():
            try:
                import winsound
                winsound.Beep(1000, 80)  # æ›´çŸ­æ›´å¿«çš„æç¤ºéŸ³
            except:
                pass

        # åœ¨å•ç‹¬çº¿ç¨‹æ’­æ”¾ï¼Œä¸é˜»å¡ä¸»å¾ªç¯
        threading.Thread(target=beep, daemon=True).start()

    def start_listening(self):
        """å¼€å§‹ç›‘å¬"""
        print("\n" + "="*60)
        print("ğŸ¤ æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹å·²å¯åŠ¨ - åŒé˜¶æ®µè¯†åˆ«æ¨¡å¼")
        print("é˜¶æ®µ1: æŒç»­ç›‘å¬å…³é”®è¯ï¼ˆè½»é‡çº§KWSï¼‰")
        print("é˜¶æ®µ2: å”¤é†’åå½•éŸ³è¯†åˆ«ï¼ˆé‡é‡çº§ASRï¼‰")
        print("æŒ‰ Ctrl+C åœæ­¢")
        print("="*60)

        self.running = True

        try:
            p = pyaudio.PyAudio()
            device_info = p.get_default_input_device_info()
            print(f"éº¦å…‹é£: {device_info['name']}")

            # æ‰“å¼€éŸ³é¢‘æµ
            stream = p.open(
                format=pyaudio.paFloat32,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=CHUNK_SIZE
            )

            print("âœ“ å¼€å§‹ç›‘å¬å…³é”®è¯...\n")

            # åˆ›å»ºKWSæµ
            kws_stream = self.kws_model.create_stream()

            while self.running:
                try:
                    # è¯»å–éŸ³é¢‘
                    audio_bytes = stream.read(CHUNK_SIZE, exception_on_overflow=False)
                    audio_data = np.frombuffer(audio_bytes, dtype=np.float32)

                    # TTSæ’­æ”¾æœŸé—´ä»ç„¶ç›‘å¬ï¼ˆå…è®¸æ‰“æ–­ï¼‰
                    if self.agent.tts.is_playing:
                        # æ£€æµ‹éŸ³é‡å³°å€¼ï¼Œåˆ¤æ–­æ˜¯å¦æ˜¯çœŸå®çš„è¯­éŸ³æ‰“æ–­
                        volume = np.sqrt(np.mean(audio_data**2))
                        # å¦‚æœéŸ³é‡è¿‡ä½ï¼ˆå¯èƒ½æ˜¯TTSå›å£°ï¼‰ï¼Œè·³è¿‡æ£€æµ‹
                        if volume < 0.02:  # é™ä½é˜ˆå€¼ï¼Œæ›´å®¹æ˜“æ‰“æ–­
                            continue  # âœ“ ç§»é™¤ sleepï¼Œç«‹å³ç»§ç»­æ£€æµ‹
                        # éŸ³é‡è¶³å¤Ÿé«˜ï¼Œå¯èƒ½æ˜¯ç”¨æˆ·æ‰“æ–­ï¼Œç»§ç»­æ£€æµ‹

                    # å–‚ç»™KWS
                    kws_stream.accept_waveform(self.sample_rate, audio_data)

                    # æ£€æµ‹å…³é”®è¯
                    while self.kws_model.is_ready(kws_stream):
                        self.kws_model.decode_stream(kws_stream)

                    # è·å–ç»“æœ
                    result = self.kws_model.get_result(kws_stream)

                    if result:
                        print(f"\nâœ¨ æ£€æµ‹åˆ°å”¤é†’è¯: {result}")

                        # ç«‹å³æ’­æ”¾æœ¬åœ°æç¤ºéŸ³ï¼ˆæ— å»¶è¿Ÿï¼‰
                        self._play_beep_fast()

                        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ‰§è¡Œä»»åŠ¡
                        if self.agent.is_executing:
                            print("âš ï¸ æ­£åœ¨æ‰§è¡Œä»»åŠ¡ä¸­ï¼Œå‘é€ä¸­æ–­è¯·æ±‚...")
                            print("   ï¼ˆç­‰å¾…å½“å‰æ­¥éª¤å®Œæˆåä¸­æ–­...ï¼‰")
                            self.agent.interrupt_flag = True

                            # ç«‹å³æ‰“æ–­æ­£åœ¨æ’­æ”¾çš„TTS
                            if self.agent.tts.is_playing:
                                self.agent.tts.stop()

                            # å¿«é€Ÿç­‰å¾…ä»»åŠ¡ä¸­æ–­ï¼ˆæœ€å¤š3ç§’ï¼‰
                            wait_count = 0
                            while self.agent.is_executing and wait_count < 30:
                                time.sleep(0.1)
                                wait_count += 1

                            if self.agent.is_executing:
                                print("âš ï¸ å½“å‰æ­¥éª¤ä»åœ¨æ‰§è¡Œï¼Œå°†åœ¨ä¸‹ä¸€æ­¥ä¸­æ–­")
                            else:
                                print("âœ“ ä»»åŠ¡å·²ä¸­æ–­")

                            # é‡ç½®KWSæµï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡å”¤é†’
                            kws_stream = self.kws_model.create_stream()
                            continue

                        # ç«‹å³æ‰“æ–­æ­£åœ¨æ’­æ”¾çš„TTS
                        if self.agent.tts.is_playing:
                            self.agent.tts.stop()

                        # å¯åŠ¨å‘½ä»¤å¤„ç†çº¿ç¨‹ï¼ˆéé˜»å¡ï¼‰
                        command_thread = threading.Thread(
                            target=self._handle_command_in_thread,
                            daemon=True
                        )
                        command_thread.start()

                        # é‡ç½®KWSæµ
                        kws_stream = self.kws_model.create_stream()

                except Exception as e:
                    print(f"âš ï¸ éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
                    # é‡æ–°åˆ›å»ºæµï¼Œç»§ç»­è¿è¡Œ
                    try:
                        kws_stream = self.kws_model.create_stream()
                    except:
                        pass
                    continue

            stream.stop_stream()
            stream.close()
            p.terminate()

        except KeyboardInterrupt:
            print("\nåœæ­¢ä¸­...")
        finally:
            self.running = False
            # åœæ­¢ MCP Server
            print("æ­£åœ¨åœæ­¢ MCP Servers...")
            self.agent.stop()
            print("âœ“ MCP Servers å·²åœæ­¢")

    def _handle_command_in_thread(self):
        """åœ¨å•ç‹¬çº¿ç¨‹ä¸­å¤„ç†å‘½ä»¤ï¼ˆéé˜»å¡ï¼‰"""
        # å°è¯•è·å–æ‰§è¡Œé”ï¼ˆå¦‚æœå·²æœ‰å‘½ä»¤åœ¨æ‰§è¡Œï¼Œç›´æ¥è¿”å›ï¼‰
        if not self.execution_lock.acquire(blocking=False):
            print("âš ï¸ å·²æœ‰å‘½ä»¤æ­£åœ¨æ‰§è¡Œï¼Œå¿½ç•¥æœ¬æ¬¡å”¤é†’")
            return

        try:
            # åˆ›å»ºç‹¬ç«‹çš„PyAudioå®ä¾‹ï¼ˆé¿å…ä¸ä¸»å¾ªç¯å†²çªï¼‰
            p = pyaudio.PyAudio()
            self._enter_command_mode(p)
            p.terminate()
        except KeyboardInterrupt:
            print("âš ï¸ ç”¨æˆ·ä¸­æ–­å‘½ä»¤å¤„ç†")
        except Exception as e:
            print(f"âš ï¸ å‘½ä»¤å¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # é‡Šæ”¾é”
            self.execution_lock.release()

    def _enter_command_mode(self, pyaudio_instance):
        """é˜¶æ®µ2: å½•éŸ³è¯†åˆ«"""
        print("ğŸ’¬ è¯·è¯´å‡ºæŒ‡ä»¤...")

        # çŸ­æš‚å»¶è¿Ÿï¼Œè®©ç”¨æˆ·å¬åˆ°Beepåå‡†å¤‡è¯´è¯
        time.sleep(0.3)

        # å½•éŸ³å‚æ•°
        audio_buffer = []

        try:
            stream = pyaudio_instance.open(
                format=pyaudio.paFloat32,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=1024
            )

            print("ğŸ™ï¸ å½•éŸ³ä¸­...")
            silence_count = 0
            frame_count = 0  # è®°å½•æ€»å¸§æ•°
            has_speech = False  # æ˜¯å¦æ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³

            for i in range(0, int(self.sample_rate / 1024 * RECORD_SECONDS)):
                audio_bytes = stream.read(1024, exception_on_overflow=False)
                audio_data = np.frombuffer(audio_bytes, dtype=np.float32)
                audio_buffer.append(audio_data)
                frame_count += 1

                # éŸ³é‡æ£€æµ‹
                volume = np.sqrt(np.mean(audio_data**2))

                # æ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³ï¼ˆéŸ³é‡è¶…è¿‡é˜ˆå€¼ï¼‰
                if volume >= SILENCE_THRESHOLD:
                    has_speech = True
                    silence_count = 0
                else:
                    # é™éŸ³å¸§
                    silence_count += 1

                    # åªæœ‰åœ¨æ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³åï¼Œæ‰å¼€å§‹é™éŸ³è®¡æ•°åœæ­¢é€»è¾‘
                    if has_speech and silence_count > MAX_SILENCE_FRAMES:
                        print("   æ£€æµ‹åˆ°é™éŸ³ï¼Œåœæ­¢å½•éŸ³")
                        break

            stream.stop_stream()
            stream.close()

            # æ‹¼æ¥éŸ³é¢‘
            full_audio = np.concatenate(audio_buffer)

            # ASRè¯†åˆ«
            print("ğŸ¤” æ­£åœ¨è¯†åˆ«...")
            asr_stream = self.asr_model.create_stream()
            asr_stream.accept_waveform(self.sample_rate, full_audio)
            self.asr_model.decode_stream(asr_stream)
            text = asr_stream.result.text.strip()

            if text:
                print(f"ğŸ“ è¯†åˆ«ç»“æœ: {text}")
                self._execute_command(text)
            else:
                print("   æœªè¯†åˆ«åˆ°å†…å®¹")
                if self.enable_voice:
                    self.agent.tts.speak_async("æŠ±æ­‰ï¼Œæˆ‘æ²¡å¬æ¸…")

        except Exception as e:
            print(f"å½•éŸ³è¯†åˆ«é”™è¯¯: {e}")

    def _execute_command(self, text):
        """æ‰§è¡Œå‘½ä»¤ï¼ˆä½¿ç”¨ React Agentï¼‰"""
        print(f"ğŸ¤– å¼€å§‹æ‰§è¡Œ: {text}")

        try:
            # ä½¿ç”¨ React Agent æ‰§è¡Œï¼ˆè‡ªåŠ¨å¤šè½®æ¨ç†ï¼‰
            result = self.agent.execute_command(text, enable_voice=self.enable_voice)

            if result.get("success"):
                print(f"âœ“ æ‰§è¡Œå®Œæˆ (å…± {result.get('steps', 0)} æ­¥)\n")
            else:
                print(f"âœ— æ‰§è¡Œå¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}\n")
        except Exception as e:
            print(f"âš ï¸ å‘½ä»¤æ‰§è¡Œå¼‚å¸¸: {e}\n")
            import traceback
            traceback.print_exc()
