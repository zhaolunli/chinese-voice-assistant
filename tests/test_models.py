"""
æµ‹è¯•å·²ä¸‹è½½çš„Sherpa-ONNXæ¨¡å‹
ä¾æ¬¡æµ‹è¯•: TTS(è¯­éŸ³åˆæˆ) â†’ STT(è¯­éŸ³è¯†åˆ«) â†’ KWS(å…³é”®è¯å”¤é†’) â†’ VAD(è¯­éŸ³æ£€æµ‹)
"""

import os
import wave
import numpy as np
import sherpa_onnx
from pathlib import Path

class ModelTester:
    def __init__(self, models_dir: str = "models"):
        self.models_dir = Path(models_dir)
        self.test_results = {}
    
    def test_tts(self):
        """æµ‹è¯•è¯­éŸ³åˆæˆï¼ˆTTSï¼‰"""
        print("\n" + "="*60)
        print("ğŸ”Š æµ‹è¯•1: è¯­éŸ³åˆæˆ (TTS)")
        print("="*60)
        
        # æŸ¥æ‰¾TTSæ¨¡å‹ç›®å½•
        tts_dirs = list(self.models_dir.glob("*melo-tts*"))
        if not tts_dirs:
            print("âŒ æœªæ‰¾åˆ°TTSæ¨¡å‹")
            print(f"   è¯·ç¡®ä¿å·²ä¸‹è½½æ¨¡å‹åˆ°: {self.models_dir.absolute()}")
            self.test_results["TTS"] = False
            return
        
        tts_dir = tts_dirs[0]
        print(f"ğŸ“ æ¨¡å‹ç›®å½•: {tts_dir.name}")
        
        try:
            # é…ç½®TTS
            config = sherpa_onnx.OfflineTtsConfig(
                model=sherpa_onnx.OfflineTtsModelConfig(
                    vits=sherpa_onnx.OfflineTtsVitsModelConfig(
                        model=str(tts_dir / "model.onnx"),
                        tokens=str(tts_dir / "tokens.txt"),
                        data_dir=str(tts_dir / "espeak-ng-data"),
                    )
                ),
                rule_fsts="",
                max_num_sentences=1,
            )
            
            # åˆ›å»ºTTSå¯¹è±¡
            tts = sherpa_onnx.OfflineTts(config)
            print(f"âœ… TTSæ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"   é‡‡æ ·ç‡: {tts.sample_rate} Hz")
            
            # æµ‹è¯•åˆæˆ
            test_texts = [
                "ä½ å¥½ï¼Œè¿™æ˜¯è¯­éŸ³åˆæˆæµ‹è¯•ã€‚",
                "æ¬¢è¿æ¥åˆ°æ™ºèƒ½ç›‘æ§å¤§å±ã€‚",
            ]
            
            for i, text in enumerate(test_texts, 1):
                print(f"\nğŸ¤ æµ‹è¯•æ–‡æœ¬ {i}: {text}")
                # ä¿®å¤APIè°ƒç”¨ï¼šä½¿ç”¨sidè€Œä¸æ˜¯speaker_id
                audio = tts.generate(text, speed=1.0, sid=0)
                
                # ä¿å­˜éŸ³é¢‘
                output_file = f"test_tts_{i}.wav"
                self._save_audio(audio.samples, tts.sample_rate, output_file)
                print(f"   âœ… å·²ç”ŸæˆéŸ³é¢‘: {output_file}")
                
                # æ’­æ”¾éŸ³é¢‘
                print(f"   ğŸ”Š æ­£åœ¨æ’­æ”¾...")
                self._play_audio(output_file)
            
            self.test_results["TTS"] = True
            print("\nâœ… TTSæµ‹è¯•é€šè¿‡ï¼")
            
        except Exception as e:
            print(f"âŒ TTSæµ‹è¯•å¤±è´¥: {e}")
            self.test_results["TTS"] = False
    
    def test_stt(self):
        """æµ‹è¯•è¯­éŸ³è¯†åˆ«ï¼ˆSTTï¼‰"""
        print("\n" + "="*60)
        print("ğŸ™ï¸ æµ‹è¯•2: è¯­éŸ³è¯†åˆ« (STT)")
        print("="*60)
        
        # æŸ¥æ‰¾STTæ¨¡å‹ç›®å½•
        stt_dirs = list(self.models_dir.glob("*paraformer*")) or \
                   list(self.models_dir.glob("*whisper*"))
        
        if not stt_dirs:
            print("âŒ æœªæ‰¾åˆ°STTæ¨¡å‹")
            self.test_results["STT"] = False
            return
        
        stt_dir = stt_dirs[0]
        print(f"ğŸ“ æ¨¡å‹ç›®å½•: {stt_dir.name}")
        
        try:
            # åˆ¤æ–­æ¨¡å‹ç±»å‹
            if "paraformer" in stt_dir.name:
                recognizer = self._create_paraformer_recognizer(stt_dir)
                model_type = "Paraformer"
            else:
                recognizer = self._create_whisper_recognizer(stt_dir)
                model_type = "Whisper"
            
            print(f"âœ… {model_type}æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"   é‡‡æ ·ç‡: {recognizer.sample_rate} Hz")
            
            # ä½¿ç”¨ä¹‹å‰TTSç”Ÿæˆçš„éŸ³é¢‘æµ‹è¯•è¯†åˆ«
            test_files = ["test_tts_1.wav", "test_tts_2.wav"]
            
            for audio_file in test_files:
                if not Path(audio_file).exists():
                    print(f"âš ï¸  æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
                    continue
                
                print(f"\nğŸ§ æµ‹è¯•æ–‡ä»¶: {audio_file}")
                text = self._recognize_audio(recognizer, audio_file)
                print(f"   ğŸ“ è¯†åˆ«ç»“æœ: {text}")
            
            self.test_results["STT"] = True
            print("\nâœ… STTæµ‹è¯•é€šè¿‡ï¼")
            
        except Exception as e:
            print(f"âŒ STTæµ‹è¯•å¤±è´¥: {e}")
            self.test_results["STT"] = False
    
    def test_kws(self):
        """æµ‹è¯•å…³é”®è¯å”¤é†’ï¼ˆKWSï¼‰"""
        print("\n" + "="*60)
        print("ğŸ¯ æµ‹è¯•3: å…³é”®è¯å”¤é†’ (KWS)")
        print("="*60)
        
        # æŸ¥æ‰¾KWSæ¨¡å‹ç›®å½•
        kws_dirs = list(self.models_dir.glob("*kws*"))
        
        if not kws_dirs:
            print("âŒ æœªæ‰¾åˆ°KWSæ¨¡å‹")
            self.test_results["KWS"] = False
            return
        
        kws_dir = kws_dirs[0]
        print(f"ğŸ“ æ¨¡å‹ç›®å½•: {kws_dir.name}")
        
        try:
            # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
            encoder = list(kws_dir.glob("*encoder*.onnx"))[0]
            decoder = list(kws_dir.glob("*decoder*.onnx"))[0]
            joiner = list(kws_dir.glob("*joiner*.onnx"))[0]
            tokens = kws_dir / "tokens.txt"
            
            # åˆ›å»ºä¸´æ—¶å…³é”®è¯æ–‡ä»¶
            keywords_file = "test_keywords.txt"
            with open(keywords_file, "w", encoding="utf-8") as f:
                f.write("å°æ™º/xiao3 zhi4/1.5\n")
                f.write("ä½ å¥½åŠ©æ‰‹/ni3 hao3 zhu4 shou3/2.0\n")
            
            print(f"âœ… KWSé…ç½®å®Œæˆ")
            print(f"   å…³é”®è¯: å°æ™º, ä½ å¥½åŠ©æ‰‹")
            print(f"   æ³¨æ„: KWSéœ€è¦å®æ—¶éŸ³é¢‘æµæµ‹è¯•ï¼Œæ­¤å¤„ä»…éªŒè¯åŠ è½½")
            
            # éªŒè¯æ–‡ä»¶å­˜åœ¨
            print(f"   Encoder: {encoder.name}")
            print(f"   Decoder: {decoder.name}")
            print(f"   Joiner: {joiner.name}")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.remove(keywords_file)
            
            self.test_results["KWS"] = True
            print("\nâœ… KWSé…ç½®æµ‹è¯•é€šè¿‡ï¼")
            print("   æç¤º: å®é™…å”¤é†’åŠŸèƒ½éœ€è¦éº¦å…‹é£å®æ—¶æµ‹è¯•")
            
        except Exception as e:
            print(f"âŒ KWSæµ‹è¯•å¤±è´¥: {e}")
            self.test_results["KWS"] = False
    
    def test_vad(self):
        """æµ‹è¯•è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆVADï¼‰"""
        print("\n" + "="*60)
        print("ğŸšï¸ æµ‹è¯•4: è¯­éŸ³æ´»åŠ¨æ£€æµ‹ (VAD)")
        print("="*60)
        
        # æŸ¥æ‰¾VADæ¨¡å‹
        vad_file = self.models_dir / "silero_vad.onnx"
        
        if not vad_file.exists():
            print("âŒ æœªæ‰¾åˆ°VADæ¨¡å‹")
            self.test_results["VAD"] = False
            return
        
        print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: {vad_file.name}")
        
        try:
            # åˆ›å»ºVADé…ç½®
            config = sherpa_onnx.VadModelConfig()
            config.silero_vad.model = str(vad_file)
            config.sample_rate = 16000
            
            vad = sherpa_onnx.VoiceActivityDetector(config, buffer_size_in_seconds=10)
            
            print(f"âœ… VADæ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"   é‡‡æ ·ç‡: 16000 Hz")
            
            # ä½¿ç”¨ä¹‹å‰çš„éŸ³é¢‘æµ‹è¯•VAD
            test_file = "test_tts_1.wav"
            if Path(test_file).exists():
                print(f"\nğŸ§ æµ‹è¯•æ–‡ä»¶: {test_file}")
                
                # è¯»å–éŸ³é¢‘
                with wave.open(test_file, 'rb') as wf:
                    sample_rate = wf.getframerate()
                    samples = np.frombuffer(wf.readframes(wf.getnframes()), dtype=np.int16)
                    samples = samples.astype(np.float32) / 32768.0
                
                # VADæ£€æµ‹
                vad.accept_waveform(samples)
                
                if vad.is_speech_detected():
                    print(f"   âœ… æ£€æµ‹åˆ°è¯­éŸ³")
                else:
                    print(f"   â„¹ï¸  æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼ˆå¯èƒ½éŸ³é¢‘å¤ªçŸ­ï¼‰")
            
            self.test_results["VAD"] = True
            print("\nâœ… VADæµ‹è¯•é€šè¿‡ï¼")
            
        except Exception as e:
            print(f"âŒ VADæµ‹è¯•å¤±è´¥: {e}")
            self.test_results["VAD"] = False
    
    # === è¾…åŠ©æ–¹æ³• ===
    
    def _create_paraformer_recognizer(self, model_dir):
        """åˆ›å»ºParaformerè¯†åˆ«å™¨"""
        # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
        encoder_files = list(model_dir.glob("*encoder*.onnx"))
        decoder_files = list(model_dir.glob("*decoder*.onnx"))
        
        if not encoder_files:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°encoderæ–‡ä»¶: {model_dir}")
        
        encoder = encoder_files[0]
        decoder = decoder_files[0] if decoder_files else None
        tokens = model_dir / "tokens.txt"
        
        config = sherpa_onnx.OfflineRecognizerConfig(
            model_config=sherpa_onnx.OfflineModelConfig(
                paraformer=sherpa_onnx.OfflineParaformerModelConfig(
                    model=str(encoder),
                ),
                tokens=str(tokens),
                num_threads=2,
            )
        )
        
        return sherpa_onnx.OfflineRecognizer(config)
    
    def _create_whisper_recognizer(self, model_dir):
        """åˆ›å»ºWhisperè¯†åˆ«å™¨"""
        encoder = model_dir / "tiny.en-encoder.onnx"
        decoder = model_dir / "tiny.en-decoder.onnx"
        tokens = model_dir / "tiny.en-tokens.txt"
        
        config = sherpa_onnx.OfflineRecognizerConfig(
            model_config=sherpa_onnx.OfflineModelConfig(
                whisper=sherpa_onnx.OfflineWhisperModelConfig(
                    encoder=str(encoder),
                    decoder=str(decoder),
                ),
                tokens=str(tokens),
                num_threads=2,
            )
        )
        
        return sherpa_onnx.OfflineRecognizer(config)
    
    def _recognize_audio(self, recognizer, audio_file):
        """è¯†åˆ«éŸ³é¢‘æ–‡ä»¶"""
        with wave.open(audio_file, 'rb') as wf:
            sample_rate = wf.getframerate()
            samples = np.frombuffer(wf.readframes(wf.getnframes()), dtype=np.int16)
            samples = samples.astype(np.float32) / 32768.0
        
        stream = recognizer.create_stream()
        stream.accept_waveform(sample_rate, samples)
        recognizer.decode_stream(stream)
        
        return stream.result.text
    
    def _save_audio(self, samples, sample_rate, filename):
        """ä¿å­˜éŸ³é¢‘æ–‡ä»¶"""
        with wave.open(filename, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(sample_rate)
            wf.writeframes((samples * 32767).astype(np.int16).tobytes())
    
    def _play_audio(self, filename):
        """æ’­æ”¾éŸ³é¢‘ï¼ˆWindowsï¼‰"""
        try:
            import winsound
            winsound.PlaySound(filename, winsound.SND_FILENAME)
        except Exception as e:
            print(f"   âš ï¸  æ’­æ”¾å¤±è´¥: {e}")
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        print("\n" + "="*60)
        print("ğŸ“Š æµ‹è¯•æ€»ç»“")
        print("="*60)
        
        for name, result in self.test_results.items():
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"  {name:15s} : {status}")
        
        success_count = sum(self.test_results.values())
        total_count = len(self.test_results)
        
        print(f"\næ€»è®¡: {success_count}/{total_count} é€šè¿‡")
        
        if success_count == total_count:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹æ„å»ºè¯­éŸ³åŠ©æ‰‹äº†ï¼")
        else:
            print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")

def main():
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘   Sherpa-ONNX æ¨¡å‹æµ‹è¯•å·¥å…·                    â•‘
    â•‘   æµ‹è¯•: TTS â†’ STT â†’ KWS â†’ VAD                â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # æ£€æŸ¥modelsç›®å½•
    models_dir = Path("models")
    if not models_dir.exists():
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {models_dir.absolute()}")
        print(f"   è¯·å…ˆè¿è¡Œ: python download_models.py")
        return
    
    print(f"ğŸ“ æ¨¡å‹ç›®å½•: {models_dir.absolute()}\n")
    print("æ¨¡å‹æ–‡ä»¶åˆ—è¡¨:")
    for item in models_dir.iterdir():
        if item.is_dir():
            print(f"  ğŸ“‚ {item.name}/")
        else:
            print(f"  ğŸ“„ {item.name}")
    
    input("\næŒ‰Enteré”®å¼€å§‹æµ‹è¯•...")
    
    # å¼€å§‹æµ‹è¯•
    tester = ModelTester()
    
    tester.test_tts()
    tester.test_stt()
    tester.test_kws()
    tester.test_vad()
    
    # æ‰“å°æ€»ç»“
    tester.print_summary()

if __name__ == "__main__":
    main()
