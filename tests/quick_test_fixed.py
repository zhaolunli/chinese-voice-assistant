"""å¿«é€Ÿæµ‹è¯•å„ä¸ªæ¨¡å‹ - å®Œå…¨ä¿®å¤ç‰ˆ"""
import sherpa_onnx
from pathlib import Path
import wave
import numpy as np

print("="*60)
print("ğŸ”Š æµ‹è¯• TTS (è¯­éŸ³åˆæˆ) - ä¸­æ–‡æµ‹è¯•")
print("="*60)

# TTSæµ‹è¯• - ä½¿ç”¨ä¸­æ–‡ï¼ˆMeloTTSæ˜¯ä¸ºä¸­æ–‡è®¾è®¡çš„ï¼‰
tts_dir = Path("models/vits-melo-tts-zh_en")
config = sherpa_onnx.OfflineTtsConfig(
    model=sherpa_onnx.OfflineTtsModelConfig(
        vits=sherpa_onnx.OfflineTtsVitsModelConfig(
            model=str(tts_dir / "model.onnx"),
            tokens=str(tts_dir / "tokens.txt"),
            data_dir=str(tts_dir / "espeak-ng-data"),
        )
    ),
    max_num_sentences=1,
)

tts = sherpa_onnx.OfflineTts(config)
print(f"âœ… TTSåŠ è½½æˆåŠŸï¼Œé‡‡æ ·ç‡: {tts.sample_rate} Hz")

# ä½¿ç”¨æ‹¼éŸ³æµ‹è¯•ï¼ˆé¿å…ç¼–ç é—®é¢˜ï¼‰
text = "ni hao shi jie"  # ä½ å¥½ä¸–ç•Œçš„æ‹¼éŸ³
print(f"ğŸ¤ ç”Ÿæˆæ–‡æœ¬: {text}")
audio = tts.generate(text, sid=0, speed=1.0)

# ä¿®å¤: å°†listè½¬æ¢ä¸ºnumpyæ•°ç»„
if isinstance(audio.samples, list):
    audio_samples = np.array(audio.samples, dtype=np.float32)
else:
    audio_samples = audio.samples

# ä¿å­˜éŸ³é¢‘
output_file = "test_output.wav"
with wave.open(output_file, 'wb') as wf:
    wf.setnchannels(1)
    wf.setsampwidth(2)
    wf.setframerate(tts.sample_rate)
    wf.writeframes((audio_samples * 32767).astype(np.int16).tobytes())

print(f"âœ… å·²ç”Ÿæˆ: {output_file}")
print(f"   æ–‡ä»¶å¤§å°: {Path(output_file).stat().st_size / 1024:.1f} KB")

# æ’­æ”¾
try:
    import winsound
    print("ğŸ”Š æ­£åœ¨æ’­æ”¾...")
    winsound.PlaySound(output_file, winsound.SND_FILENAME)
    print("âœ… æ’­æ”¾å®Œæˆ")
except Exception as e:
    print(f"âš ï¸ æ’­æ”¾å¤±è´¥: {e}")

print("\n" + "="*60)
print("ğŸ™ï¸ æµ‹è¯• STT (è¯­éŸ³è¯†åˆ«) - Paraformer")
print("="*60)

# STTæµ‹è¯• - ä¿®å¤Paraformeré…ç½®
stt_dir = Path("models/sherpa-onnx-paraformer-zh-2024-03-09")
print(f"ğŸ“ STTç›®å½•: {stt_dir}")

# ä½¿ç”¨int8é‡åŒ–æ¨¡å‹ï¼ˆæ›´å¿«ï¼‰
model_file = stt_dir / "model.int8.onnx"
tokens_file = stt_dir / "tokens.txt"

print(f"âœ… ä½¿ç”¨æ¨¡å‹: {model_file.name}")

try:
    # ä¿®å¤: ä½¿ç”¨æ­£ç¡®çš„Paraformeré…ç½®æ–¹å¼
    recognizer = sherpa_onnx.OfflineRecognizer.from_paraformer(
        paraformer=str(model_file),
        tokens=str(tokens_file),
        num_threads=2,
        sample_rate=16000,
        feature_dim=80,
        decoding_method="greedy_search",
    )
    
    print(f"âœ… STTåŠ è½½æˆåŠŸ")

    # è¯†åˆ«åˆšæ‰ç”Ÿæˆçš„éŸ³é¢‘
    print(f"ğŸ§ è¯†åˆ«éŸ³é¢‘: {output_file}")
    with wave.open(output_file, 'rb') as wf:
        sample_rate = wf.getframerate()
        samples = np.frombuffer(wf.readframes(wf.getnframes()), dtype=np.int16)
        samples = samples.astype(np.float32) / 32768.0
    
    print(f"   åŸå§‹é‡‡æ ·ç‡: {sample_rate} Hz")
    print(f"   éŸ³é¢‘é•¿åº¦: {len(samples) / sample_rate:.2f} ç§’")

    stream = recognizer.create_stream()
    stream.accept_waveform(sample_rate, samples)
    recognizer.decode_stream(stream)

    result = stream.result.text
    print(f"ğŸ“ è¯†åˆ«ç»“æœ: '{result}'")
    
    if result.strip():
        print("âœ… STTè¯†åˆ«æˆåŠŸï¼")
    else:
        print("âš ï¸ è¯†åˆ«ç»“æœä¸ºç©ºï¼ˆå¯èƒ½éŸ³é¢‘å†…å®¹ä¸æ˜¯ä¸­æ–‡è¯­éŸ³ï¼‰")
        
except Exception as e:
    print(f"âŒ STTæµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "="*60)
print("ğŸšï¸ æµ‹è¯• VAD (è¯­éŸ³æ´»åŠ¨æ£€æµ‹)")
print("="*60)

vad_file = Path("models/silero_vad.onnx")
config = sherpa_onnx.VadModelConfig()
config.silero_vad.model = str(vad_file)
config.sample_rate = 16000

vad = sherpa_onnx.VoiceActivityDetector(config, buffer_size_in_seconds=10)
print(f"âœ… VADåŠ è½½æˆåŠŸ")

print("\n" + "="*60)
print("ğŸ‰ æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
print("="*60)
print("\nğŸ’¡ æç¤º:")
print("1. TTSä½¿ç”¨æ‹¼éŸ³è¾“å…¥å¯é¿å…ä¸­æ–‡ç¼–ç é—®é¢˜")
print("2. ä¹Ÿå¯ä»¥ç›´æ¥åœ¨Pythonä¸­ä½¿ç”¨ä¸­æ–‡å­—ç¬¦ä¸²")
print("3. æµ‹è¯•éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜: test_output.wav")
print("4. å¯ä»¥ç”¨Windows Media Playerç­‰æ’­æ”¾å™¨æ‰“å¼€æŸ¥çœ‹")
